{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Used a lot of code out of the examples of ipycanvas\n",
    "\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "from ipywidgets import HBox, VBox, IntSlider, Image, Text, Label, RadioButtons, Button, Output, Tab, FloatSlider, FileUpload, Dropdown\n",
    "\n",
    "from mmgen.apis import init_model, sample_uncoditional_model  # isort:skip  # noqa\n",
    "from mmgen.models.architectures import positional_encoding\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def displace(inputs, level):\n",
    "    # return torch.from_numpy(ndimage.rotate(inputs, x, axes=axes,reshape=False))\n",
    "    if level:\n",
    "        return inputs + torch.normal(0, level/1000,size=inputs.shape)\n",
    "    else:\n",
    "        return inputs\n",
    "\n",
    "\n",
    "def warp(inputs, base_x, base_y, magnitude=1):\n",
    "    new_img = torch.zeros_like(inputs)\n",
    "    new_img[0] = (inputs[0] - base_x)\n",
    "    new_img[1] = (inputs[1] - base_y)\n",
    "\n",
    "    distances = torch.sqrt(new_img[0]**2 + new_img[1]**2) \n",
    "\n",
    "    new_img[0] = base_x + new_img[0]/distances * (distances ** magnitude) # /new_img[0]**2\n",
    "    new_img[1] = base_y + new_img[1]/distances * (distances ** magnitude) # /new_img[1]**2\n",
    "    return new_img\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dislevel = 0\n",
    "x,y = 0, 0\n",
    "size = 1024\n",
    "no_points = 10\n",
    "is_style=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FFHQ_ScaleParty', 'FFHQ_ScaleParty.zip']\n",
      "0.2\n",
      "Use load_from_local loader\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for generator.injected_noise_0: copying a param with shape torch.Size([1, 1, 4, 4]) from checkpoint, the shape in current model is torch.Size([1, 1, 8, 8]).\n",
      "size mismatch for generator.injected_noise_1: copying a param with shape torch.Size([1, 1, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 1, 14, 14]).\n",
      "size mismatch for generator.injected_noise_2: copying a param with shape torch.Size([1, 1, 8, 8]) from checkpoint, the shape in current model is torch.Size([1, 1, 12, 12]).\n",
      "size mismatch for generator.injected_noise_3: copying a param with shape torch.Size([1, 1, 18, 18]) from checkpoint, the shape in current model is torch.Size([1, 1, 22, 22]).\n",
      "size mismatch for generator.injected_noise_4: copying a param with shape torch.Size([1, 1, 16, 16]) from checkpoint, the shape in current model is torch.Size([1, 1, 20, 20]).\n",
      "size mismatch for generator.injected_noise_5: copying a param with shape torch.Size([1, 1, 34, 34]) from checkpoint, the shape in current model is torch.Size([1, 1, 38, 38]).\n",
      "size mismatch for generator.injected_noise_6: copying a param with shape torch.Size([1, 1, 32, 32]) from checkpoint, the shape in current model is torch.Size([1, 1, 36, 36]).\n",
      "size mismatch for generator.injected_noise_7: copying a param with shape torch.Size([1, 1, 66, 66]) from checkpoint, the shape in current model is torch.Size([1, 1, 70, 70]).\n",
      "size mismatch for generator.injected_noise_8: copying a param with shape torch.Size([1, 1, 64, 64]) from checkpoint, the shape in current model is torch.Size([1, 1, 68, 68]).\n",
      "size mismatch for generator.injected_noise_9: copying a param with shape torch.Size([1, 1, 130, 130]) from checkpoint, the shape in current model is torch.Size([1, 1, 134, 134]).\n",
      "size mismatch for generator.injected_noise_10: copying a param with shape torch.Size([1, 1, 128, 128]) from checkpoint, the shape in current model is torch.Size([1, 1, 132, 132]).\n",
      "size mismatch for generator.injected_noise_11: copying a param with shape torch.Size([1, 1, 258, 258]) from checkpoint, the shape in current model is torch.Size([1, 1, 262, 262]).\n",
      "size mismatch for generator.injected_noise_12: copying a param with shape torch.Size([1, 1, 256, 256]) from checkpoint, the shape in current model is torch.Size([1, 1, 260, 260]).\n",
      "size mismatch for generator_ema.injected_noise_0: copying a param with shape torch.Size([1, 1, 4, 4]) from checkpoint, the shape in current model is torch.Size([1, 1, 8, 8]).\n",
      "size mismatch for generator_ema.injected_noise_1: copying a param with shape torch.Size([1, 1, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 1, 14, 14]).\n",
      "size mismatch for generator_ema.injected_noise_2: copying a param with shape torch.Size([1, 1, 8, 8]) from checkpoint, the shape in current model is torch.Size([1, 1, 12, 12]).\n",
      "size mismatch for generator_ema.injected_noise_3: copying a param with shape torch.Size([1, 1, 18, 18]) from checkpoint, the shape in current model is torch.Size([1, 1, 22, 22]).\n",
      "size mismatch for generator_ema.injected_noise_4: copying a param with shape torch.Size([1, 1, 16, 16]) from checkpoint, the shape in current model is torch.Size([1, 1, 20, 20]).\n",
      "size mismatch for generator_ema.injected_noise_5: copying a param with shape torch.Size([1, 1, 34, 34]) from checkpoint, the shape in current model is torch.Size([1, 1, 38, 38]).\n",
      "size mismatch for generator_ema.injected_noise_6: copying a param with shape torch.Size([1, 1, 32, 32]) from checkpoint, the shape in current model is torch.Size([1, 1, 36, 36]).\n",
      "size mismatch for generator_ema.injected_noise_7: copying a param with shape torch.Size([1, 1, 66, 66]) from checkpoint, the shape in current model is torch.Size([1, 1, 70, 70]).\n",
      "size mismatch for generator_ema.injected_noise_8: copying a param with shape torch.Size([1, 1, 64, 64]) from checkpoint, the shape in current model is torch.Size([1, 1, 68, 68]).\n",
      "size mismatch for generator_ema.injected_noise_9: copying a param with shape torch.Size([1, 1, 130, 130]) from checkpoint, the shape in current model is torch.Size([1, 1, 134, 134]).\n",
      "size mismatch for generator_ema.injected_noise_10: copying a param with shape torch.Size([1, 1, 128, 128]) from checkpoint, the shape in current model is torch.Size([1, 1, 132, 132]).\n",
      "size mismatch for generator_ema.injected_noise_11: copying a param with shape torch.Size([1, 1, 258, 258]) from checkpoint, the shape in current model is torch.Size([1, 1, 262, 262]).\n",
      "size mismatch for generator_ema.injected_noise_12: copying a param with shape torch.Size([1, 1, 256, 256]) from checkpoint, the shape in current model is torch.Size([1, 1, 260, 260]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 15:55:25,584 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "2022-06-06 15:55:25,585 - mmgen - INFO - Switch to evaluation style mode: single\n"
     ]
    }
   ],
   "source": [
    "model_list = sorted(list(os.listdir(\"checkpoints\")))\n",
    "print(model_list)\n",
    "def load_model(run_name):\n",
    "    config = f\"configs/scaleparty/{run_name}.py\"\n",
    "    ckpt = f\"checkpoints/{run_name}/ckpt/latest.pth\"\n",
    "    device='cpu' if not torch.has_cuda else \"cuda\"\n",
    "    use_noise = True\n",
    "\n",
    "\n",
    "    model = init_model(\n",
    "        config, checkpoint=ckpt, device=device)\n",
    "\n",
    "    get_pos = model.generator.head_pos_enc.make_grid2d\n",
    "    return model, get_pos, config\n",
    "\n",
    "model, get_pos, config = load_model(model_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = Canvas(width=512, height=512)\n",
    "canvas.fill_style = '#584f4e'\n",
    "canvas.fill_rect(128, 128, 256, 256)\n",
    "\n",
    "warp_x = 256\n",
    "warp_y = 256\n",
    "\n",
    "\n",
    "objects_to_draw = []\n",
    "positions = None \n",
    "class Square_obj():\n",
    "    def __init__(self, x,y, width=5, height=5, append_self = True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.selected = False\n",
    "        if append_self:\n",
    "            objects_to_draw.append(self)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def set_x_y(self,x_in,y_in)  :\n",
    "        self.x = x_in\n",
    "        self.y = y_in\n",
    "    \n",
    "    def draw(self, padding=False):\n",
    "        \n",
    "        # canvas.fill_style = '#38a8a4'\n",
    "        # canvas.fill_rect(self.x - (self.width*0.5), self.y - (self.height) , self.width, self.height)\n",
    "        if padding:\n",
    "            canvas.fill_style = '#dd2e06'\n",
    "        else:\n",
    "            canvas.fill_style = '#2edd0c'\n",
    "        canvas.fill_rect(self.x - (self.width*0.5), self.y - (self.height*0.5) , self.width, self.height)\n",
    "        # canvas.fill_circle(x,y,radius=self.width)\n",
    "\n",
    "        \n",
    "        \n",
    "    def is_selected(self,x_in, y_in):\n",
    "        x_coord = self.x - (self.width*0.5)\n",
    "        y_coord = self.y - (self.height*0.5)\n",
    "\n",
    "        if x_in > x_coord and x_in < (x_coord+ self.width) and  y_in > y_coord  and y_in < (y_coord  + self.height):\n",
    "            \n",
    "            self.set_selected(True)\n",
    "            return True\n",
    "        else:\n",
    "            self.set_selected(False)\n",
    "            return False\n",
    "    \n",
    "    def set_selected(self,state):\n",
    "        self.selected = state\n",
    "\n",
    "class Warp_obj(Square_obj):\n",
    "    def __init__(self, x, y, width=5, height=5):\n",
    "        super().__init__(x, y, width=width, height=height, append_self=False)\n",
    "\n",
    "    def draw(self):\n",
    "        canvas.fill_style = \"#deaaaa\"\n",
    "        canvas.fill_rect(self.x - (self.width*0.5), self.y - (self.height*0.5) , self.width, self.height)\n",
    "\n",
    "def canvas_restart():\n",
    "    canvas.clear()\n",
    "    canvas.fill_style = '#584f4e'\n",
    "    canvas.fill_rect(128, 128, 256, 256)\n",
    "\n",
    "def canvas_init(x,y,size,dislevel,number, ratio=1.0, magnitude=1.0):\n",
    "    global positions\n",
    "    global warpoint\n",
    "    canvas_restart()\n",
    "\n",
    "    size_x = size\n",
    "    size_y = size*ratio\n",
    "\n",
    "    positions = get_pos(n_height=number-6, \n",
    "                        n_width=number-6,\n",
    "                        start_w=(x-size_x/2),\n",
    "                        start_h=(y-size_y/2),\n",
    "                        width=size_x,\n",
    "                        height=size_y\n",
    "                        )[0]\n",
    "    \n",
    "\n",
    "\n",
    "    positions = displace(positions, dislevel)\n",
    "     \n",
    "    positions = warp(positions, (warpoint.x - 256)/128, (warpoint.y-256)/128, magnitude=magnitude)\n",
    "\n",
    "    positions = torch.nan_to_num(positions)\n",
    "    with hold_canvas(canvas):\n",
    "        cnt = 0\n",
    "        for pos in positions.view(2,number**2).transpose(0,1):\n",
    "            x,y = pos.numpy()\n",
    "            s=Square_obj(x*128 + 256 ,y*128 + 256)\n",
    "            s.set_selected(False)\n",
    "            s.draw(padding= (cnt % number) < 3 or (cnt % number > number - 4) or (cnt // number < 3) or (cnt // number > number - 4))\n",
    "            cnt += 1\n",
    "    warpoint.draw()\n",
    "\n",
    "def handle_mouse_up(x, y):\n",
    "    global warpoint\n",
    "    warpoint.set_selected(False)\n",
    "\n",
    "\n",
    "def handle_mouse_down(x, y):\n",
    "    global warpoint, warp_x, warp_y\n",
    "    \n",
    "    warp_y = y\n",
    "    warp_x = x\n",
    "    \n",
    "\n",
    "    warpoint.set_x_y(x,y)\n",
    "\n",
    "    on_slider_change()\n",
    "\n",
    "\n",
    "def handle_mouse_move(x, y):    \n",
    "    global warpoint\n",
    "    warpoint.set_x_y(x,y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warpoint = Warp_obj(warp_x, warp_y)\n",
    "warpoint.set_selected = True \n",
    "warpoint.draw()\n",
    "\n",
    "# canvas.on_mouse_move(handle_mouse_move)\n",
    "# canvas.on_mouse_up(handle_mouse_up)\n",
    "\n",
    "canvas_init(0.5,0.5,1.,0,10)\n",
    "canvas.on_mouse_down(handle_mouse_down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from interactive_utils import generate\n",
    "\n",
    "# latent = get_latent(g_ema, n_samples=1)\n",
    "# mean_latent = model.get_mean_latent(args.truncation_mean, device = device)\n",
    "if \"mspie\" in config:\n",
    "    latent = model(None, num_batches=1, chosen_scale=0, return_latents=True)[\"noise_batch\"]\n",
    "else:\n",
    "    latent = model.generator.get_noise(1)\n",
    "\n",
    "is_style=False\n",
    "def generate():\n",
    "\n",
    "    extra = dict(truncation=0.7)\n",
    "    if \"mspie\" in config:\n",
    "        results = model.generator_ema(\n",
    "            latent, num_batches=1, chosen_scale=slider_number.value-10,\n",
    "            truncation=slider_trunc.value)\n",
    "    else:\n",
    "        results = model.generator_ema(\n",
    "            latent, num_batches=1, chosen_scale=slider_number.value-10, input_is_latent = is_style,\n",
    "            positional_enc = positions.unsqueeze(0),truncation=slider_trunc.value)\n",
    " \n",
    "\n",
    "    results = (results[:, [2, 1, 0]] + 1.) / 2.\n",
    "\n",
    "    return results[0].detach().cpu().numpy().transpose((1,2,0))\n",
    "\n",
    "\n",
    "out = Output()\n",
    "t = Tab()\n",
    "t.children = [out]\n",
    "\n",
    "plt.ioff()\n",
    "ax=plt.gca()\n",
    "ax.figure.set_size_inches((8,8))\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.ion()\n",
    "with out:\n",
    "    warnings. simplefilter(\"ignore\")\n",
    "    ax.imshow(generate())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_size = Label(\n",
    "    value='Zoom',\n",
    "    placeholder='Image size',\n",
    "    description='String: pick the size of the image',\n",
    "    disabled=False\n",
    ")\n",
    "slider_size = FloatSlider(min=0.2, max =2.5, value= 1.0,step=0.01)\n",
    "\n",
    "text_ratio = Label(\n",
    "    value='Aspect ratio',\n",
    "    placeholder='Image ratio',\n",
    "    description='String: pick the ratio of the image',\n",
    "    disabled=False\n",
    ")\n",
    "slider_ratio = FloatSlider(min=0.2, max =5, value= 1, step = 0.1)\n",
    "\n",
    "text_attract = Label(\n",
    "    value='Attract magnitude',\n",
    "    placeholder='Image attract',\n",
    "    description='String: pick the attract of the image',\n",
    "    disabled=False\n",
    ")\n",
    "slider_attract = FloatSlider(min=0.2, max =5, value= 1, step = 0.1)\n",
    "\n",
    "text_x = Label(\n",
    "    value='Position x',\n",
    "    placeholder='Image x',\n",
    "    description='String: pick the x of the image',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "slider_x = FloatSlider(min=-0.5, max =1.5, value = 0.5, step=0.01)\n",
    "\n",
    "text_y = Label(\n",
    "    value='Position y',\n",
    "    placeholder='Image y',\n",
    "    description='String: pick the y of the image',\n",
    "    disabled=False\n",
    ")\n",
    "slider_y = FloatSlider(min=-0.5, max =1.5, value = 0.5, step=0.01)\n",
    "\n",
    "text_rotation = Label(\n",
    "    value='Noisy displacement',\n",
    "    placeholder='Image rotation',\n",
    "    description='String: pick the rotation of the image',\n",
    "    disabled=False\n",
    ")\n",
    "slider_rotation = IntSlider(min=0, max =360)\n",
    "\n",
    "text_number = Label(\n",
    "    value='Number or points (NxN)',\n",
    "    placeholder='Image number',\n",
    "    description='String: pick the number of the image',\n",
    "    disabled=False\n",
    ")\n",
    "slider_number = IntSlider(min=7, max =24, value= 12)\n",
    "\n",
    "click_options = RadioButtons(\n",
    "    options=['Move', 'Attract', 'Repel'],\n",
    "#    value='pineapple', # Defaults to 'pineapple'\n",
    "#    layout={'width': 'max-content'}, # If the items' names are long\n",
    "    description='Click behavior:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "gen_button = Button(\n",
    "    description='Generate',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "latent_button = Button(\n",
    "    description='Sample Latent',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "fuploader = FileUpload(\n",
    "    accept='.pkl',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=False  # True to accept multiple files upload else False\n",
    ")\n",
    "\n",
    "model_dropdown = Dropdown(\n",
    "    options = model_list,\n",
    "    value=model_list[0],\n",
    "    disabled=False\n",
    "    )\n",
    "\n",
    "text_trunc = Label(\n",
    "    value='Truncation',\n",
    "    description='level of truncation for latent code',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "slider_trunc = FloatSlider(min=0.0, max =1.0, value = 0.8, step=0.05)\n",
    "\n",
    "\n",
    "def on_slider_change(change=None):\n",
    "    canvas_init(slider_x.value, slider_y.value, slider_size.value, slider_rotation.value, slider_number.value, slider_ratio.value, slider_attract.value)\n",
    "\n",
    "@out.capture()\n",
    "def on_generate_click(button):\n",
    "    global tmp_img\n",
    "    ax.clear()\n",
    "    tmp_img = generate()\n",
    "    ax.imshow(tmp_img)\n",
    "    # plt.clear()\n",
    "    with out:\n",
    "        # im.set_data(generate())\n",
    "        clear_output(wait=True)\n",
    "        # fig.canvas.draw_idle()\n",
    "        # ax.show()\n",
    "        # plt.show()\n",
    "        display(ax.figure)\n",
    "    # fig.canvas.flush_events()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def on_latent_click(button):\n",
    "    global latent\n",
    "    # latent = get_latent(g_ema, n_samples=1)\n",
    "    # latent = model.get_mean_latent()\n",
    "    if \"mspie\" in config:\n",
    "        latent = model(None, num_batches=1, chosen_scale=0, return_latents=True)[\"noise_batch\"]\n",
    "    else:\n",
    "        latent = model.generator.get_noise(1)\n",
    "\n",
    "def on_upload_change(change):\n",
    "    global latent\n",
    "    latent = torch.load(fuploader.value)\n",
    "\n",
    "def on_dropdown_change(change):\n",
    "    global model, get_pos, config\n",
    "    model, get_pos, config = load_model(model_dropdown.value)\n",
    "\n",
    "\n",
    "slider_x.observe(on_slider_change, 'value')\n",
    "slider_y.observe(on_slider_change, 'value')\n",
    "slider_size.observe(on_slider_change, 'value')\n",
    "slider_ratio.observe(on_slider_change, 'value')\n",
    "slider_attract.observe(on_slider_change, 'value')\n",
    "slider_rotation.observe(on_slider_change, 'value')\n",
    "slider_number.observe(on_slider_change, 'value')\n",
    "\n",
    "fuploader.observe(on_upload_change, names='_counter')\n",
    "\n",
    "model_dropdown.observe(on_dropdown_change, 'value')\n",
    "\n",
    "\n",
    "latent_button.on_click(on_latent_click)\n",
    "gen_button.on_click(on_generate_click)\n",
    "\n",
    "buttons = HBox((latent_button, gen_button))\n",
    "trunc_box = HBox((text_trunc, slider_trunc))\n",
    "controls = VBox((text_x, slider_x, text_y, slider_y, text_size, slider_size, text_ratio, slider_ratio, text_rotation, slider_rotation, text_number, slider_number, text_attract, slider_attract, buttons, model_dropdown, trunc_box))\n",
    "# controls = VBox((text_x, slider_x, text_y, slider_y, text_size, slider_size, text_ratio, slider_ratio, text_number, slider_number, text_attract, slider_attract, buttons, model_dropdown, trunc_box))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with different configuration of positional encodings\n",
    "\n",
    "The networks was trained with different crops of images at 256 and 384 pixel resolution. The crops were between 60% and 110% of the scale of a full-portrait. \n",
    "Which mean that the network has seen during training full-frame resolution of ~232px to 640px. However, it was never trained to generate a full-frame images larger than 384. Going beyond the 232-640 scale range can produce erroneous results. Moreover, the _aspect ratio_ and _attract magnitude_ will also produce configurations unseen during training. Use noisy displacement for some trippy results :D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2510a045f4e4e9e8157218afc499947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=512, width=512), VBox(children=(Label(value='Position x', description='String: piâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "is_style=False\n",
    "display(HBox([canvas, controls, out]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No image data to save, please be sure that ``sync_image_data`` is set to True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-afd936d4e03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"visuals/{imgname}_posenc.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/ipycanvas/canvas.py\u001b[0m in \u001b[0;36mto_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No image data to save, please be sure that ``sync_image_data`` is set to True'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can only save to a PNG file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No image data to save, please be sure that ``sync_image_data`` is set to True"
     ]
    }
   ],
   "source": [
    "canvas.sync_image_data = True\n",
    "imgname = \"scaleparty_sample\"\n",
    "from PIL import Image\n",
    "\n",
    "canvas.to_file(f\"visuals/{imgname}_posenc.png\")\n",
    "\n",
    "\n",
    "im = Image.fromarray((255*np.clip(tmp_img,0,1)).astype(np.uint8))\n",
    "\n",
    "im.save(f\"visuals/{imgname}_img.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d114926a6ffcb5a4e25bb9f03304dd8beae18e17a0e4b949b471672e589122e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
